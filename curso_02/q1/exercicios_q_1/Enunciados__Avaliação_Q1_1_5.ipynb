{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "median-importance",
      "metadata": {
        "id": "median-importance"
      },
      "source": [
        "#**CURSO 2 - CIENCIA DE DADOS, APRENDIZADO DE MÁQUINA E DATA MINING**\n",
        "## **PROFa. Roseli A F Romero**\n",
        "\n",
        "# **Exploração de dados**\n",
        "\n",
        "Para os exercícios de 1) a 4), considere a base de dados de jogadores de futebol (`jogadores_exercicio1.csv`).\n",
        "\n",
        "\n",
        "### **Questão 01**.\n",
        "\n",
        "#Com base nos valores da média e desvio padrão dos atributos `weight` e `age` podemos dizer que:\n",
        "\n",
        "a) o desvio padrão do atributo `weight` corresponde a menos de 10% da sua média<br>\n",
        "b) o desvio padrão do atributo `age` corresponde a mais de 20% da sua média<br>\n",
        "c) não há praticamente nenhuma variação nos dados dos atributos `weight` e `age`<br>\n",
        "d) nenhuma das anteriores\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "recreational-journalism",
      "metadata": {
        "id": "recreational-journalism"
      },
      "source": [
        "---\n",
        "### **Questão 02**.\n",
        "\n",
        "Considerando o histograma do atributo `weight`, podemos afirmar que:\n",
        "\n",
        "a) a maioria dos dados estão entre 60 e 70<br>\n",
        "b) a maioria dos dados estão entre 65 e 85<br>\n",
        "c) os dados apresentam uma distribuição uniforme<br>\n",
        "d) nenhuma das anteriores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "damaged-facility",
      "metadata": {
        "id": "damaged-facility"
      },
      "source": [
        "---\n",
        "### **Questão 03**.\n",
        "\n",
        "Considerando o boxplot do atributo `age`, podemos afirmar que:\n",
        "\n",
        "a) o valor que separa 75% dos dados (terceiro quartil) é maior que 40<br>\n",
        "b) o valor que separa 25% dos dados (primeiro quartil) é menor que 30<br>\n",
        "c) existe ao menos um outlier nesse conjunto<br>\n",
        "d) nenhuma das anteriores"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cardiac-taxation",
      "metadata": {
        "id": "cardiac-taxation"
      },
      "source": [
        "---\n",
        "\n",
        "### **Questão 04**.\n",
        "\n",
        "Considere os dados abaixo armazenados na variável `data`. Ao normalizá-los entre 0 e 1, qual o valor da segunda linha?\n",
        "<!-- Suponha que cada coluna seja um atributo diferente e aplique a normalização sobre cada coluna separadamente. -->\n",
        "\n",
        "a) 2, 0.85, 0.33<br>\n",
        "b) 1.0, 0., 0.7<br>\n",
        "c) 15.5, 0.45, 0.8<br>\n",
        "d) nenhuma das anteriores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rtlVdsMqPP4b",
      "metadata": {
        "id": "rtlVdsMqPP4b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "data = np.array([\n",
        "        [15, 28, 30],\n",
        "        [410, -2.5, 65],\n",
        "        [5, 30, 80]\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "afraid-stewart",
      "metadata": {
        "id": "afraid-stewart"
      },
      "source": [
        "---\n",
        "\n",
        "### **Questão 05**.\n",
        "\n",
        "Para essa questão, utilizaremos o dataset `boston house prices`.\n",
        "\n",
        "Ler o conjunto de dados usando os seguintes comandos:\n",
        "\n",
        "data_url = \"http://lib.stat.cmu.edu/datasets/boston\" <br>\n",
        "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None) <br>\n",
        "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]]) <br>\n",
        "y = raw_df.values[1::2, 2] <br>\n",
        "\n",
        "1.   Dividir o dataset em 80% treino e 20% teste (com `random_state=0`)\n",
        "2.   Padronizar os dados utilizando `StandardScaler`\n",
        "3.   Aplicar a técnica `PCA` e reduzir a dimensionalidade dos atributos para 2\n",
        "\n",
        "\n",
        "O que se pode afirmar sobre as porcentagens da variância que cada componente principal armazena:\n",
        "\n",
        "a) A porcentagem da 1a. componente: PCA1 = 33.45% é maior que a porcentagem da 2a. componente principal: PCA2=21% <br>\n",
        "b) A porcentagem da 2a. componente: PCA2 = 31.11% é maior que a porcentagem da 1a. componente principal: PCA1 = 20.22%<br>\n",
        "c) A porcentagem da 1a. componente: PCA1 = 47% é maior que a porcentagem da 2a. componente principal: PCA2=11% <br>\n",
        "d) A porcentagem da 1a. componente: PCA1=20.22% nem sempre é maior que a da 2a. componente principal: PCA2= 31.11%.\n",
        "\n",
        "\n",
        "\n",
        "#### Observações\n",
        "- Lembre-se de utilizar apenas o conjunto de **treino** para fit do `PCA`, `StandardScaler` e considerar aproximação para 2 casas decimais.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
